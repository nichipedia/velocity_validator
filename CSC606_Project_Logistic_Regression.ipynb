{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb73820-9f99-476a-a290-3b24fd469f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee12a798-36a3-4ad0-aa56-4147f6500ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CSV file of curated/merged data\n",
    "df = pd.read_csv('c:/csc606/curated colocated data/merged_velocity_data.csv',low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8fe61f-d0ad-48ee-8998-f421069409eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create single column in dataframe called \"key\" that concatenates leg, site, hole, core, section fields to a single key field.\n",
    "# The key column will be used for joining/merging later\n",
    "df['key']=df['leg'] + \".\" + df['site'] + \".\" + df['hole'] + \".\" + df['core'] + \".\" + df['section']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c2b88d-041a-413c-a6fa-e4dd9041ef52",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231a9a5f-9adf-4839-a78f-36253bad7ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CSV file of Taylor's labeled data\n",
    "labeled_df = pd.read_csv('c:/csc606/image_assessment_augmented.csv',low_memory=False)\n",
    "\n",
    "# convert int columns to str\n",
    "labeled_df['leg']=labeled_df['leg'].astype(str)\n",
    "labeled_df['site']=labeled_df['site'].astype(str)\n",
    "labeled_df['hole']=labeled_df['hole'].astype(str)\n",
    "labeled_df['core']=labeled_df['core'].astype(str)\n",
    "labeled_df['section']=labeled_df['section'].astype(str)\n",
    "\n",
    "# Create single column in dataframe called \"key\" that concatenates leg, site, hole, core, section fields to a single key field.\n",
    "# The key column will be used for joining/merging later\n",
    "labeled_df['key']=labeled_df['leg'] + \".\" + labeled_df['site'] + \".\" + labeled_df['hole'] + \".\" + labeled_df['core'] + \".\" + labeled_df['section']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b212fc8c-f036-4ddb-9a49-bad889291051",
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea88834e-6b32-4741-9a67-94c71268eebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fc753a-2b0e-4f70-9a61-5eff63f0176e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we merge the labeled dataset with the curated dataset\n",
    "merged_labeled_df = pd.merge(labeled_df, df, on='key', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51663703-d07e-4efd-b3ee-eb523a1dce8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_labeled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ae1f80-a209-4204-8356-7b29a0e046b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we create the features:  mean/mode/median/std/min/max for both depth and compressional velocity\n",
    "# we also create the 25%(Q1) and 75%(Q3) quantiles for compressional velocity within the section\n",
    "groupby_columns = ['key','greater_than_50_percent_bad']\n",
    "df_grouped = merged_labeled_df.groupby(groupby_columns)[['depth_m','compressional_velocity(m/s)']].agg(\n",
    "    depth_mean=('depth_m','mean'),\n",
    "    depth_median=('depth_m','median'),\n",
    "    depth_mode=('depth_m',lambda x: x.mode()[0]),\n",
    "    depth_std=('depth_m', 'std'),\n",
    "    depth_min=('depth_m', 'min'),\n",
    "    depth_max=('depth_m', 'max'),\n",
    "    velocity_mean=('compressional_velocity(m/s)','mean'),\n",
    "    velocity_median=('compressional_velocity(m/s)','median'),\n",
    "    velocity_mode=('compressional_velocity(m/s)',lambda x: x.mode()[0]),\n",
    "    velocity_std=('compressional_velocity(m/s)', 'std'),\n",
    "    velocity_min=('compressional_velocity(m/s)', 'min'),\n",
    "    velocity_max=('compressional_velocity(m/s)', 'max'),\n",
    "    velocity_q1 =('compressional_velocity(m/s)',lambda x: x.quantile(0.25)),\n",
    "    velocity_q3 =('compressional_velocity(m/s)',lambda x: x.quantile(0.75))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6bd827-f526-486e-b523-b1cfc5e0b6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a33ca6-e4f7-416b-a839-4cbf41872f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the interquartile range for compressional velocity between Q1 and Q3\n",
    "# calculate upper and lower boundaries for compressional velocity which are 1.5x the IGR above the median\n",
    "#   and 1.5x the IGR below the median\n",
    "df_grouped['velocity_igr'] = df_grouped['velocity_q3']-df_grouped['velocity_q1']\n",
    "df_grouped['velocity_upper'] = df_grouped['velocity_median'] + (df_grouped['velocity_igr']*1.5)\n",
    "df_grouped['velocity_lower'] = df_grouped['velocity_median'] - (df_grouped['velocity_igr']*1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b09dd87-eb13-4630-8737-4d9bddce643b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd90b7f9-79a6-4307-81f8-4596dcda9fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get rid of the indexes created by groupby\n",
    "df_grouped = df_grouped.reset_index()\n",
    "\n",
    "# convert the boolean label to numeric 1 and 0\n",
    "df_grouped['label'] = df_grouped['greater_than_50_percent_bad'].astype(int)\n",
    "df_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a3119d-11e5-4355-843e-15c0706d6ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull out the key identifiers to X_identifiers, since they are text and can't be a feature, but we need them later\n",
    "# drop the label columns and the key\n",
    "X_identifiers = df_grouped['key']\n",
    "X = df_grouped.drop('greater_than_50_percent_bad', axis=1).drop('key', axis=1).drop('label', axis=1)\n",
    "\n",
    "# create the labeled series from the label column\n",
    "y = df_grouped['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611559b4-7467-4ba1-9465-b8a9aaba4d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff75c0d-9a6f-43bd-8845-0f9c6f8bebaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model selection of Logistic Regression\n",
    "model = LogisticRegression(max_iter=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8406bc2-aa12-464f-95bc-432969947c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Training\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5df903-d5dc-4dfe-8d86-99ec0f35edf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model prediction using the test dataset\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4572dd-33f0-4cc2-a561-858bdc063248",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate prediction probabilities from test dataset\n",
    "y_pred_prob = model.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993852b6-9ab5-4eda-89ad-b171c3b25120",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6006f7-8291-45c7-a1ce-37983974881c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy and create a classification report having precision, recall, f1 score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b020c2c-9a76-411c-b47a-8e05e5c2acef",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(\"\\nClassification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57723e1-b529-494f-8525-472976da4442",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build confusion matrix for the test dataset\n",
    "conf_mat = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=conf_mat,\n",
    "                              display_labels=model.classes_)\n",
    "disp.plot()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a5806baf-e603-4640-8a2b-05856a87ce27",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
